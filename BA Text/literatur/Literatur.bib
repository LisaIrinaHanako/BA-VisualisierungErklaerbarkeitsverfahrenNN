
@article{montavonExplainingNonlinearClassification2017,
	title = {Explaining nonlinear classification decisions with deep {Taylor} decomposition},
	volume = {65},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320316303582},
	doi = {10.1016/j.patcog.2016.11.008},
	abstract = {Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets.},
	urldate = {2020-11-26},
	journal = {Pattern Recognition},
	author = {Montavon, Grégoire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and Müller, Klaus-Robert},
	month = may,
	year = {2017},
	keywords = {Deep neural networks, Heatmapping, Image recognition, Relevance propagation, Taylor decomposition, Deep Taylor Decomposition},
	pages = {211--222},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Lisa\\Zotero\\storage\\5HAFWK68\\Montavon et al. - 2017 - Explaining nonlinear classification decisions with.pdf:application/pdf},
}

@article{MontavonLRP,
	title = {Methods for interpreting and understanding deep neural networks},
	volume = {73},
	issn = {1051-2004},
	url = {http://www.sciencedirect.com/science/article/pii/S1051200417302385},
	doi = {10.1016/j.dsp.2017.10.011},
	abstract = {This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. As a tutorial paper, the set of methods covered here is not exhaustive, but sufficiently representative to discuss a number of questions in interpretability, technical challenges, and possible applications. The second part of the tutorial focuses on the recently proposed layer-wise relevance propagation (LRP) technique, for which we provide theory, recommendations, and tricks, to make most efficient use of it on real data.},
	urldate = {2020-11-27},
	journal = {Digital Signal Processing},
	author = {Montavon, Grégoire and Samek, Wojciech and Müller, Klaus-Robert},
	month = feb,
	year = {2018},
	keywords = {Deep neural networks, Taylor decomposition, Activation maximization, Layer-wise relevance propagation, Sensitivity analysis, in proposal},
	pages = {1--15},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Lisa\\Zotero\\storage\\XGSW66US\\Montavon et al. - 2018 - Methods for interpreting and understanding deep ne.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\AECAM9TI\\S1051200417302385.html:text/html},
}

@article{BachPixelwise,
	title = {On {Pixel}-{Wise} {Explanations} for {Non}-{Linear} {Classifier} {Decisions} by {Layer}-{Wise} {Relevance} {Propagation}},
	volume = {10},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140},
	doi = {10.1371/journal.pone.0130140},
	abstract = {Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.},
	number = {7},
	urldate = {2020-11-27},
	journal = {PLOS ONE},
	author = {Bach, Sebastian and Binder, Alexander and Montavon, Grégoire and Klauschen, Frederick and Müller, Klaus-Robert and Samek, Wojciech},
	month = jul,
	year = {2015},
	keywords = {in proposal, Algorithms, Coding mechanisms, Imaging techniques, Kernel functions, Neural networks, Neurons, Sensory perception, Vision},
	file = {Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\2KRTIK6J\\article.html:text/html;Full Text PDF:C\:\\Users\\Lisa\\Zotero\\storage\\2AVWWCEI\\Bach et al. - 2015 - On Pixel-Wise Explanations for Non-Linear Classifi.pdf:application/pdf;Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\7CLQT6R5\\article.html:text/html},
}

@incollection{montavonLayerWiseRelevancePropagation2019,
	address = {Cham},
	title = {Layer-{Wise} {Relevance} {Propagation}: {An} {Overview}},
	volume = {11700},
	isbn = {978-3-030-28953-9 978-3-030-28954-6},
	shorttitle = {Layer-{Wise} {Relevance} {Propagation}},
	url = {http://link.springer.com/10.1007/978-3-030-28954-6_10},
	urldate = {2020-11-27},
	booktitle = {Explainable {AI}: {Interpreting}, {Explaining} and {Visualizing} {Deep} {Learning}},
	publisher = {Springer International Publishing},
	author = {Montavon, Grégoire and Binder, Alexander and Lapuschkin, Sebastian and Samek, Wojciech and Müller, Klaus-Robert},
	editor = {Samek, Wojciech and Montavon, Grégoire and Vedaldi, Andrea and Hansen, Lars Kai and Müller, Klaus-Robert},
	year = {2019},
	doi = {10.1007/978-3-030-28954-6_10},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {193--209},
}

@article{SHAPDeepExplainer Shrikumar,
	title = {Learning {Important} {Features} {Through} {Propagating} {Activation} {Differences}},
	url = {http://arxiv.org/abs/1704.02685},
	abstract = {The purported "black box" nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. Video tutorial: http://goo.gl/qKb7pL, ICML slides: bit.ly/deeplifticmlslides, ICML talk: https://vimeo.com/238275076, code: http://goo.gl/RM8jvH.},
	urldate = {2020-12-09},
	journal = {arXiv:1704.02685 [cs]},
	author = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
	month = oct,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, in proposal},
	annote = {Comment: Updated to include changes present in the ICML camera-ready paper, and other small corrections},
	file = {arXiv Fulltext PDF:C\:\\Users\\Lisa\\Zotero\\storage\\PE7A2766\\Shrikumar et al. - 2019 - Learning Important Features Through Propagating Ac.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\UHJNKL9V\\1704.html:text/html},
}

@article{LundbergSHAPDeepExplainer,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
	urldate = {2020-12-10},
	journal = {Advances in Neural Information Processing Systems},
	author = {Lundberg, Scott M. and Lee, Su-In},
	year = {2017},
	keywords = {in proposal, deeplift, SHAP, deep SHAP},
	pages = {4765--4774},
	file = {Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\2YER4UBA\\8a20a8621978632d76c43dfd28b67767-Abstract.html:text/html;Full Text PDF:C\:\\Users\\Lisa\\Zotero\\storage\\E5XFSNQT\\Lundberg und Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf:application/pdf;Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\XD3E6UVX\\8a20a8621978632d76c43dfd28b67767-Abstract.html:text/html},
}

@article{lundbergLocalExplanationsGlobal2020,
	title = {From local explanations to global understanding with explainable {AI} for trees},
	volume = {2},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-019-0138-9},
	doi = {10.1038/s42256-019-0138-9},
	abstract = {Tree-based machine learning models such as random forests, decision trees and gradient boosted trees are popular nonlinear predictive models, yet comparatively little attention has been paid to explaining their predictions. Here we improve the interpretability of tree-based models through three main contributions. (1) A polynomial time algorithm to compute optimal explanations based on game theory. (2) A new type of explanation that directly measures local feature interaction effects. (3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to (1) identify high-magnitude but low-frequency nonlinear mortality risk factors in the US population, (2) highlight distinct population subgroups with shared risk characteristics, (3) identify nonlinear interaction effects among risk factors for chronic kidney disease and (4) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model’s performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains.},
	number = {1},
	urldate = {2020-12-10},
	journal = {Nature Machine Intelligence},
	author = {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
	month = jan,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {56--67},
	file = {Akzeptierte Version:C\:\\Users\\Lisa\\Zotero\\storage\\4UQN9XVS\\Lundberg et al. - 2020 - From local explanations to global understanding wi.pdf:application/pdf;Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\ZA4DZ4SV\\s42256-019-0138-9.html:text/html},
}

@article{lundbergExplainableMachinelearningPredictions2018,
	title = {Explainable machine-learning predictions for the prevention of hypoxaemia during surgery},
	volume = {2},
	copyright = {2018 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2157-846X},
	url = {https://www.nature.com/articles/s41551-018-0304-0},
	doi = {10.1038/s41551-018-0304-0},
	abstract = {Although anaesthesiologists strive to avoid hypoxaemia during surgery, reliably predicting future intraoperative hypoxaemia is not possible at present. Here, we report the development and testing of a machine-learning-based system that predicts the risk of hypoxaemia and provides explanations of the risk factors in real time during general anaesthesia. The system, which was trained on minute-by-minute data from the electronic medical records of over 50,000 surgeries, improved the performance of anaesthesiologists by providing interpretable hypoxaemia risks and contributing factors. The explanations for the predictions are broadly consistent with the literature and with prior knowledge from anaesthesiologists. Our results suggest that if anaesthesiologists currently anticipate 15\% of hypoxaemia events, with the assistance of this system they could anticipate 30\%, a large portion of which may benefit from early intervention because they are associated with modifiable factors. The system can help improve the clinical understanding of hypoxaemia risk during anaesthesia care by providing general insights into the exact changes in risk induced by certain characteristics of the patient or procedure.},
	number = {10},
	urldate = {2020-12-10},
	journal = {Nature Biomedical Engineering},
	author = {Lundberg, Scott M. and Nair, Bala and Vavilala, Monica S. and Horibe, Mayumi and Eisses, Michael J. and Adams, Trevor and Liston, David E. and Low, Daniel King-Wai and Newman, Shu-Fang and Kim, Jerry and Lee, Su-In},
	month = oct,
	year = {2018},
	note = {Number: 10
Publisher: Nature Publishing Group},
	pages = {749--760},
	file = {Akzeptierte Version:C\:\\Users\\Lisa\\Zotero\\storage\\DPPK59VJ\\Lundberg et al. - 2018 - Explainable machine-learning predictions for the p.pdf:application/pdf;Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\I5MLMA6L\\s41551-018-0304-0.html:text/html},
}

@article{MothilalDiCE,
	title = {Explaining {Machine} {Learning} {Classifiers} through {Diverse} {Counterfactual} {Explanations}},
	url = {http://arxiv.org/abs/1905.07697},
	doi = {10.1145/3351095.3372850},
	abstract = {Post-hoc explanations of machine learning models are crucial for people to understand and act on algorithmic predictions. An intriguing class of explanations is through counterfactuals, hypothetical examples that show people how to obtain a different prediction. We posit that effective counterfactual explanations should satisfy two properties: feasibility of the counterfactual actions given user context and constraints, and diversity among the counterfactuals presented. To this end, we propose a framework for generating and evaluating a diverse set of counterfactual explanations based on determinantal point processes. To evaluate the actionability of counterfactuals, we provide metrics that enable comparison of counterfactual-based methods to other local explanation methods. We further address necessary tradeoffs and point to causal implications in optimizing for counterfactuals. Our experiments on four real-world datasets show that our framework can generate a set of counterfactuals that are diverse and well approximate local decision boundaries, outperforming prior approaches to generating diverse counterfactuals. We provide an implementation of the framework at https://github.com/microsoft/DiCE.},
	urldate = {2020-12-11},
	journal = {arXiv:1905.07697 [cs, stat]},
	author = {Mothilal, Ramaravind Kommiya and Sharma, Amit and Tan, Chenhao},
	month = dec,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, in proposal, Computer Science - Computers and Society, DiCE},
	annote = {Comment: 13 pages},
	file = {arXiv Fulltext PDF:C\:\\Users\\Lisa\\Zotero\\storage\\8CL2PAID\\Mothilal et al. - 2019 - Explaining Machine Learning Classifiers through Di.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\VC222BE5\\1905.html:text/html},
}

@article{WachterCounterfactuals,
	title = {Counterfactual {Explanations} without {Opening} the {Black} {Box}: {Automated} {Decisions} and the {GDPR}},
	issn = {1556-5068},
	shorttitle = {Counterfactual {Explanations} without {Opening} the {Black} {Box}},
	url = {http://arxiv.org/abs/1711.00399},
	doi = {10.2139/ssrn.3063289},
	abstract = {There has been much discussion of the right to explanation in the EU General Data Protection Regulation, and its existence, merits, and disadvantages. Implementing a right to explanation that opens the black box of algorithmic decision-making faces major legal and technical barriers. Explaining the functionality of complex algorithmic decision-making systems and their rationale in specific cases is a technically challenging problem. Some explanations may offer little meaningful information to data subjects, raising questions around their value. Explanations of automated decisions need not hinge on the general public understanding how algorithmic systems function. Even though such interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the black box. Looking at explanations as a means to help a data subject act rather than merely understand, one could gauge the scope and content of explanations according to the specific goal or action they are intended to support. From the perspective of individuals affected by automated decision-making, we propose three aims for explanations: (1) to inform and help the individual understand why a particular decision was reached, (2) to provide grounds to contest the decision if the outcome is undesired, and (3) to understand what would need to change in order to receive a desired result in the future, based on the current decision-making model. We assess how each of these goals finds support in the GDPR. We suggest data controllers should offer a particular type of explanation, unconditional counterfactual explanations, to support these three aims. These counterfactual explanations describe the smallest change to the world that can be made to obtain a desirable outcome, or to arrive at the closest possible world, without needing to explain the internal logic of the system.},
	urldate = {2020-12-11},
	journal = {SSRN Electronic Journal},
	author = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
	month = mar,
	year = {2018},
	keywords = {Computer Science - Artificial Intelligence, in proposal, Basics, Counterfactuals, Wachter, DiCE},
	file = {arXiv Fulltext PDF:C\:\\Users\\Lisa\\Zotero\\storage\\T5CRK76D\\Wachter et al. - 2018 - Counterfactual Explanations without Opening the Bl.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\4J5J3HWG\\1711.html:text/html},
}

@article{MahajanDiCe,
	title = {Preserving {Causal} {Constraints} in {Counterfactual} {Explanations} for {Machine} {Learning} {Classifiers}},
	url = {http://arxiv.org/abs/1912.03277},
	abstract = {To construct interpretable explanations that are consistent with the original ML model, counterfactual examples---showing how the model's output changes with small perturbations to the input---have been proposed. This paper extends the work in counterfactual explanations by addressing the challenge of feasibility of such examples. For explanations of ML models in critical domains such as healthcare and finance, counterfactual examples are useful for an end-user only to the extent that perturbation of feature inputs is feasible in the real world. We formulate the problem of feasibility as preserving causal relationships among input features and present a method that uses (partial) structural causal models to generate actionable counterfactuals. When feasibility constraints cannot be easily expressed, we consider an alternative mechanism where people can label generated CF examples on feasibility: whether it is feasible to intervene and realize the candidate CF example from the original input. To learn from this labelled feasibility data, we propose a modified variational auto encoder loss for generating CF examples that optimizes for feasibility as people interact with its output. Our experiments on Bayesian networks and the widely used ''Adult-Income'' dataset show that our proposed methods can generate counterfactual explanations that better satisfy feasibility constraints than existing methods.. Code repository can be accessed here: {\textbackslash}textit\{https://github.com/divyat09/cf-feasibility\}},
	urldate = {2020-12-11},
	journal = {arXiv:1912.03277 [cs, stat]},
	author = {Mahajan, Divyat and Tan, Chenhao and Sharma, Amit},
	month = jun,
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, in proposal, DiCE},
	annote = {Comment: 2019 NeurIPS Workshop on Do the right thing: Machine learning and Causal Inference for improved decision making},
	file = {Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\B9N26N9C\\preserving-causal-constraints-in-counterfactual-explanations-for-machine-learning-classifiers.html:text/html;arXiv Fulltext PDF:C\:\\Users\\Lisa\\Zotero\\storage\\E7N8T75N\\Mahajan et al. - 2020 - Preserving Causal Constraints in Counterfactual Ex.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\BP9JYFNG\\1912.html:text/html},
}

@article{sklearn-ML-Paper,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simpliﬁed BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	journal = {MACHINE LEARNING IN PYTHON},
	author = {Pedregosa, Fabian and Varoquaux, Gael and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David},
	keywords = {Decision Tree, Paper},
	pages = {6},
	file = {Pedregosa et al. - Scikit-learn Machine Learning in Python.pdf:C\:\\Users\\Lisa\\Zotero\\storage\\U8RJA9ET\\Pedregosa et al. - Scikit-learn Machine Learning in Python.pdf:application/pdf},
}

@article{sklearn-API-Paper,
	title = {{API} design for machine learning software: experiences from the scikit-learn project},
	shorttitle = {{API} design for machine learning software},
	url = {http://arxiv.org/abs/1309.0238},
	abstract = {Scikit-learn is an increasingly popular machine learning li- brary. Written in Python, it is designed to be simple and efficient, accessible to non-experts, and reusable in various contexts. In this paper, we present and discuss our design choices for the application programming interface (API) of the project. In particular, we describe the simple and elegant interface shared by all learning and processing units in the library and then discuss its advantages in terms of composition and reusability. The paper also comments on implementation details specific to the Python ecosystem and analyzes obstacles faced by users and developers of the library.},
	urldate = {2021-01-14},
	journal = {arXiv:1309.0238 [cs]},
	author = {Buitinck, Lars and Louppe, Gilles and Blondel, Mathieu and Pedregosa, Fabian and Mueller, Andreas and Grisel, Olivier and Niculae, Vlad and Prettenhofer, Peter and Gramfort, Alexandre and Grobler, Jaques and Layton, Robert and Vanderplas, Jake and Joly, Arnaud and Holt, Brian and Varoquaux, Gaël},
	month = sep,
	year = {2013},
	keywords = {Computer Science - Machine Learning, Logistic Regression, footnote, Decision Tree, Paper, Computer Science - Mathematical Software, Doku, LASSO},
	file = {arXiv Fulltext PDF:C\:\\Users\\Lisa\\Zotero\\storage\\EQT29XTA\\Buitinck et al. - 2013 - API design for machine learning software experien.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\52T3HJ3J\\1309.html:text/html},
}

@article{FatF-Paper,
	title = {{FAT} {Forensics}: {A} {Python} {Toolbox} for {Implementing} and {Deploying} {Fairness}, {Accountability} and {Transparency} {Algorithms} in {Predictive} {Systems}},
	volume = {5},
	issn = {2475-9066},
	shorttitle = {{FAT} {Forensics}},
	url = {https://joss.theoj.org/papers/10.21105/joss.01904},
	doi = {10.21105/joss.01904},
	abstract = {Machine learning algorithms can take important decisions, sometimes legally binding, about our everyday life. In most cases, however, these systems and decisions are neither regulated nor certified. Given the potential harm that these algorithms can cause, qualities such as fairness, accountability and transparency of predictive systems are of paramount importance. Recent literature suggested voluntary self-reporting on these aspects of predictive systems -- e.g., data sheets for data sets -- but their scope is often limited to a single component of a machine learning pipeline, and producing them requires manual labour. To resolve this impasse and ensure high-quality, fair, transparent and reliable machine learning systems, we developed an open source toolbox that can inspect selected fairness, accountability and transparency aspects of these systems to automatically and objectively report them back to their engineers and users. We describe design, scope and usage examples of this Python toolbox in this paper. The toolbox provides functionality for inspecting fairness, accountability and transparency of all aspects of the machine learning process: data (and their features), models and predictions. It is available to the public under the BSD 3-Clause open source licence.},
	number = {49},
	urldate = {2021-01-18},
	journal = {Journal of Open Source Software},
	author = {Sokol, Kacper and Hepburn, Alexander and Poyiadzi, Rafael and Clifford, Matthew and Santos-Rodriguez, Raul and Flach, Peter},
	month = may,
	year = {2020},
	keywords = {Counterfactuals},
	pages = {1904},
	file = {Full Text PDF:C\:\\Users\\Lisa\\Zotero\\storage\\T8AK2GVF\\Sokol et al. - 2020 - FAT Forensics A Python Toolbox for Implementing a.pdf:application/pdf;Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\28TQA3UI\\joss.html:text/html},
}

@misc{Ridge Lasso Elastic Net,
	title = {({Tutorial}) {Regularization}: {Ridge}, {Lasso} and {Elastic} {Net}},
	shorttitle = {({Tutorial}) {Regularization}},
	url = {https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net},
	abstract = {Learn how REGULARIZATION solves the bias-variance trade-off problem in linear REGRESSION, diving into RIDGE, LASSO, and ELASTIC NET!},
	urldate = {2021-01-18},
	journal = {DataCamp Community},
	month = nov,
	year = {2019},
	file = {Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\J4A63HAD\\tutorial-ridge-lasso-elastic-net.html:text/html},
}

@misc{MLBook-CF,
	title = {6.1 {Counterfactual} {Explanations} {\textbar} {Interpretable} {Machine} {Learning}},
	url = {https://christophm.github.io/interpretable-ml-book/counterfactual.html},
	urldate = {2021-01-18},
	keywords = {Counterfactuals},
	file = {6.1 Counterfactual Explanations | Interpretable Machine Learning:C\:\\Users\\Lisa\\Zotero\\storage\\7N4XSQ2T\\counterfactual.html:text/html},
}

@book{MLBook-interpretable,
	title = {4.2 {Logistic} {Regression} {\textbar} {Interpretable} {Machine} {Learning}},
	url = {https://christophm.github.io/interpretable-ml-book/logistic.html},
	abstract = {Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.},
	urldate = {2021-01-18},
	author = {Molnar, Christoph},
	keywords = {LASSO, Lineares Modell, logistische Regression, Regularisierung},
	file = {Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\CJDJIERA\\logistic.html:text/html},
}

@book{Basics-Statistik-Sachs,
	address = {München},
	edition = {5. Auflage},
	series = {Mathematik-{Studienhilfen}},
	title = {Wahrscheinlichkeitsrechnung und {Statistik}: für {Ingenieurstudierende} an {Hochschulen}: mit 35 {Bildern}, 93 {Beispielen} und 71 {Aufgaben}},
	isbn = {978-3-446-45163-6 978-3-446-45620-4},
	shorttitle = {Wahrscheinlichkeitsrechnung und {Statistik}},
	publisher = {Fachbuchverlag Leipzig im Carl Hanser Verlag},
	author = {Sachs, Michael},
	year = {2018},
	keywords = {Grundlagen, Statistik},
	file = {Sachs - 2018 - Wahrscheinlichkeitsrechnung und Statistik für Ing.pdf:C\:\\Users\\Lisa\\Zotero\\storage\\YMLGMT6H\\Sachs - 2018 - Wahrscheinlichkeitsrechnung und Statistik für Ing.pdf:application/pdf},
}

@book{Basics-Statistik-Cramer,
	series = {Springer-lehrbuch},
	title = {Grundlagen der wahrscheinlichkeitsrechnung und statistik: {Ein} skript für studierende der informatik, der ingenieur- und wirtschaftswissenschaften},
	isbn = {978-3-662-43973-9},
	url = {https://books.google.co.jp/books?id=trkhBAAAQBAJ},
	publisher = {Springer Berlin Heidelberg},
	author = {Cramer, E. and Kamps, U.},
	year = {2014},
	keywords = {Grundlagen, Statistik},
	file = {Cramer und Kamps - 2014 - Grundlagen der wahrscheinlichkeitsrechnung und sta.pdf:C\:\\Users\\Lisa\\Zotero\\storage\\AL6VNVKQ\\Cramer und Kamps - 2014 - Grundlagen der wahrscheinlichkeitsrechnung und sta.pdf:application/pdf},
}

@article{Basics-KI-Definition,
	title = {Introduction to the {Transactions} on {Interactive} {Intelligent} {Systems}},
	volume = {1},
	issn = {2160-6455, 2160-6463},
	url = {https://dl.acm.org/doi/10.1145/2030365.2030366},
	doi = {10.1145/2030365.2030366},
	number = {1},
	urldate = {2021-02-11},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Jameson, Anthony and Riedl, John},
	month = oct,
	year = {2011},
	pages = {1--6},
	file = {Jameson und Riedl - 2011 - Introduction to the Transactions on Interactive In.pdf:C\:\\Users\\Lisa\\Zotero\\storage\\H4XVNSEI\\Jameson und Riedl - 2011 - Introduction to the Transactions on Interactive In.pdf:application/pdf},
}

@book{Basics-ML,
	title = {Foundations of {Machine} {Learning}, second edition},
	isbn = {978-0-262-35136-2},
	abstract = {A new edition of a graduate-level machine learning textbook that focuses on the analysis and theory of algorithms.This book is a general introduction to machine learning that can serve as a textbook for graduate students and a reference for researchers. It covers fundamental modern topics in machine learning while providing the theoretical basis and conceptual tools needed for the discussion and justification of algorithms. It also describes several key aspects of the application of these algorithms. The authors aim to present novel theoretical tools and concepts while giving concise proofs even for relatively advanced topics. Foundations of Machine Learning is unique in its focus on the analysis and theory of algorithms. The first four chapters lay the theoretical foundation for what follows; subsequent chapters are mostly self-contained. Topics covered include the Probably Approximately Correct (PAC) learning framework; generalization bounds based on Rademacher complexity and VC-dimension; Support Vector Machines (SVMs); kernel methods; boosting; on-line learning; multi-class classification; ranking; regression; algorithmic stability; dimensionality reduction; learning automata and languages; and reinforcement learning. Each chapter ends with a set of exercises. Appendixes provide additional material including concise probability review.This second edition offers three new chapters, on model selection, maximum entropy models, and conditional entropy models. New material in the appendixes includes a major section on Fenchel duality, expanded coverage of concentration inequalities, and an entirely new entry on information theory. More than half of the exercises are new to this edition.},
	publisher = {MIT Press},
	author = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
	month = dec,
	year = {2018},
	keywords = {Basics, Computers / Intelligence (AI) \& Semantics, ML},
}

@book{Basics-ML2,
	title = {Machine {Learning} in {Radiation} {Oncology}: {Theory} and {Applications}},
	isbn = {978-3-319-18305-3},
	shorttitle = {Machine {Learning} in {Radiation} {Oncology}},
	abstract = {​This book provides a complete overview of the role of machine learning in radiation oncology and medical physics, covering basic theory, methods, and a variety of applications in medical physics and radiotherapy. An introductory section explains machine learning, reviews supervised and unsupervised learning methods, discusses performance evaluation, and summarizes potential applications in radiation oncology. Detailed individual sections are then devoted to the use of machine learning in quality assurance; computer-aided detection, including treatment planning and contouring; image-guided radiotherapy; respiratory motion management; and treatment response modeling and outcome prediction. The book will be invaluable for students and residents in medical physics and radiation oncology and will also appeal to more experienced practitioners and researchers and members of applied machine learning communities.},
	publisher = {Springer},
	author = {Naqa, Issam El and Li, Ruijiang and Murphy, Martin J.},
	month = jun,
	year = {2015},
	keywords = {Basics, ML, Medical / Clinical Medicine, Medical / Radiology, Radiotherapy \& Nuclear Medicine, Science / Life Sciences / Biophysics, Science / Radiation},
}

@misc{Basics-ML-Blog,
	title = {Wie lernen {Maschinen}? - {Grundlegende} {Begriffe} - {ML}-{Blog} • {Grundlagen}},
	shorttitle = {Wie lernen {Maschinen}?},
	url = {https://machinelearning-blog.de/grundlagen/wie-maschinen-lernen/},
	abstract = {Maschinelles Lernen ist längst zum festen Bestandteil unserer Welt geworden und verändert unser Leben. Wir erklären, wie Maschinen lernen.},
	urldate = {2021-02-16},
	journal = {ML-Blog},
	month = jan,
	year = {2021},
	keywords = {Basics, ML},
	file = {Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\CENC8BL8\\wie-maschinen-lernen.html:text/html},
}

@misc{Basics-(un/semi)supervised,
	title = {Welche {Arten} von {Maschinellem} {Lernen} gibt es?},
	url = {https://machinelearning-blog.de/grundlagen/welche-arten-von-maschinellem-lernen-gibt-es/},
	abstract = {Es gibt verschiedene Arten von Maschinellem Lernen nach denen Algorithmen trainiert werden (supervised, unsupervised, semi-supervised, reinforcement und active learning).},
	urldate = {2021-02-16},
	journal = {ML-Blog},
	month = jan,
	year = {2021},
	keywords = {Basics, semi-supervised, supervised, unsupervised},
	file = {Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\5MGAEL49\\welche-arten-von-maschinellem-lernen-gibt-es.html:text/html},
}

@article{Basics-CNN,
	title = {Convolutional neural networks: an overview and application in radiology},
	volume = {9},
	issn = {1869-4101},
	shorttitle = {Convolutional neural networks},
	url = {https://doi.org/10.1007/s13244-018-0639-9},
	doi = {10.1007/s13244-018-0639-9},
	abstract = {Convolutional neural network (CNN), a class of artificial neural networks that has become dominant in various computer vision tasks, is attracting interest across a variety of domains, including radiology. CNN is designed to automatically and adaptively learn spatial hierarchies of features through backpropagation by using multiple building blocks, such as convolution layers, pooling layers, and fully connected layers. This review article offers a perspective on the basic concepts of CNN and its application to various radiological tasks, and discusses its challenges and future directions in the field of radiology. Two challenges in applying CNN to radiological tasks, small dataset and overfitting, will also be covered in this article, as well as techniques to minimize them. Being familiar with the concepts and advantages, as well as limitations, of CNN is essential to leverage its potential in diagnostic radiology, with the goal of augmenting the performance of radiologists and improving patient care.},
	number = {4},
	urldate = {2021-02-17},
	journal = {Insights into Imaging},
	author = {Yamashita, Rikiya and Nishio, Mizuho and Do, Richard Kinh Gian and Togashi, Kaori},
	month = aug,
	year = {2018},
	keywords = {Basics, CNN, Definition},
	pages = {611--629},
	file = {Springer Full Text PDF:C\:\\Users\\Lisa\\Zotero\\storage\\NLS965KZ\\Yamashita et al. - 2018 - Convolutional neural networks an overview and app.pdf:application/pdf},
}

@article{Basics-RNN,
	title = {Recurrent {Neural} {Networks}},
	author = {Bullinaria, John A},
	keywords = {Basics, Definition, RNN},
	pages = {20},
	file = {Bullinaria - Recurrent Neural Networks.pdf:C\:\\Users\\Lisa\\Zotero\\storage\\WVA72H9M\\Bullinaria - Recurrent Neural Networks.pdf:application/pdf},
}

@article{Basics-ANN-NN-RNN,
	title = {A {BRIEF} {REVIEW} {OF} {FEED}-{FORWARD} {NEURAL} {NETWORKS}},
	abstract = {Artificial neural networks, or shortly neural networks, find applications in a very wide spectrum. In this paper, following a brief presentation of the basic aspects of feed-forward neural networks, their mostly used learning/training algorithm, the so-called back-propagation algorithm, have been described.},
	author = {Sazli, Murat H},
	keywords = {Basics, Definition, RNN, ANN, NN},
	pages = {7},
	file = {Sazli - A BRIEF REVIEW OF FEED-FORWARD NEURAL NETWORKS.pdf:C\:\\Users\\Lisa\\Zotero\\storage\\7G3LS8FT\\Sazli - A BRIEF REVIEW OF FEED-FORWARD NEURAL NETWORKS.pdf:application/pdf},
}

@book{Basics-Learningrate-Graphs,
	title = {Hands-{On} {Machine} {Learning} with {Scikit}-{Learn}, {Keras}, and {TensorFlow}: {Concepts}, {Tools}, and {Techniques} to {Build} {Intelligent} {Systems}},
	isbn = {978-1-4920-3261-8},
	shorttitle = {Hands-{On} {Machine} {Learning} with {Scikit}-{Learn}, {Keras}, and {TensorFlow}},
	abstract = {Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how.By using concrete examples, minimal theory, and two production-ready Python frameworks—Scikit-Learn and TensorFlow—author Aurélien Géron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You’ll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With exercises in each chapter to help you apply what you’ve learned, all you need is programming experience to get started.Explore the machine learning landscape, particularly neural netsUse Scikit-Learn to track an example machine-learning project end-to-endExplore several training models, including support vector machines, decision trees, random forests, and ensemble methodsUse the TensorFlow library to build and train neural netsDive into neural net architectures, including convolutional nets, recurrent nets, and deep reinforcement learningLearn techniques for training and scaling deep neural nets},
	publisher = {"O'Reilly Media, Inc."},
	author = {Géron, Aurélien},
	month = sep,
	year = {2019},
	keywords = {Basics, Computers / Intelligence (AI) \& Semantics, Computers / Computer Vision \& Pattern Recognition, Computers / Data Processing, Computers / Natural Language Processing, Computers / Neural Networks, Computers / Programming Languages / Python, Graphs, LearningRate, Visuals},
}

@article{Basics-Training-Daten-ehler-CrossValidation,
	title = {Neuronale {Netze} und {Tiefe} {Architekturen}},
	author = {Wurm, Christian},
	keywords = {Basics, Fehlerfunktion, Trainingsdaten, Testdaten, Crossvalidation},
	pages = {139},
	file = {Wurm - Neuronale Netze und Tiefe Architekturen.pdf:C\:\\Users\\Lisa\\Zotero\\storage\\HSLCI9YH\\Wurm - Neuronale Netze und Tiefe Architekturen.pdf:application/pdf},
}

@inproceedings{Basics-Linear,
	address = {Cham},
	series = {Lecture {Notes} in {Computational} {Vision} and {Biomechanics}},
	title = {E-health {Design} with {Spectral} {Analysis}, {Linear} {Layer} {Neural} {Networks} and {Adaboost} {Classifier} for {Epilepsy} {Classification} from {EEG} {Signals}},
	isbn = {978-3-319-71767-8},
	doi = {10.1007/978-3-319-71767-8_55},
	abstract = {About 1–2\% of the population in the whole world is suffering from a serious neurological disorder called epilepsy which is characterized by spontaneous seizures. A lot of temporary disruptions occur in the ongoing electrical activities of the brain if the seizure attack is present. Antiepileptic drugs may be favourable for some patients while for other patients it may not respond well. To explore the electrical behaviour of the human brain, the measurement and the recordings of the electrical brain activity is done. By analyzing the Electroencephalography (EEG) signals and extracting all its features including both univariate and multivariate, various algorithms for seizure prediction, detection, classification have been developed. In this paper, an e-health design for epilepsy classification with the help of spectral analysis, Linear Layer Neural Networks (LLNN) and Adaboost Classifier has been proposed. The LLNN has been used as the preliminary level classifier and as the results obtained through it are not satisfactory, further optimization and classification is done with the help of Adaboost Classifier. Results show that when classified with Adaboost Classifier an average classification accuracy of about 99.43\%, an average quality value of 24.38, an average less time delay of 1.99 s along with an average performance index of 99.13\% is obtained.},
	booktitle = {Computational {Vision} and {Bio} {Inspired} {Computing}},
	publisher = {Springer International Publishing},
	author = {Rajaguru, Harikumar and Prabhakar, Sunil Kumar},
	editor = {Hemanth, D. Jude and Smys, S.},
	year = {2018},
	keywords = {Basics, Adaboost, EEG, Epilepsy, LLNN, Linear Layer, Schichten},
	pages = {634--640},
	file = {Springer Full Text PDF:C\:\\Users\\Lisa\\Zotero\\storage\\9X7FX8LR\\Rajaguru und Prabhakar - 2018 - E-health Design with Spectral Analysis, Linear Lay.pdf:application/pdf},
}

@inproceedings{Basics-Softmax-Hardware,
	title = {Efficient {Hardware} {Architecture} of {Softmax} {Layer} in {Deep} {Neural} {Network}},
	doi = {10.1109/ICDSP.2018.8631588},
	abstract = {Deep neural network (DNN), as a very important machine learning technique in classification and detection tasks for images, video, speech as wellas audio, has recently received tremendous attention. Integral Stochastic Computation (Integral SC), on the other hand, has proved its extraordinary ability in hardware implementation of DNNs. Thesoftmax layer is generally used in multi-classification tasks as a very basic and important network layer in DNNs. However, the hardware implementation of softmax layer is expensive cause the exponentiation and division computation. In this paper, we designed an efficient way to simulate softmax layer in DNNs based on Integral stochastic computing, filling the vacancy of previous academic works. Compared to conventional softmax hardware implementation, our method achieves reduction in power and area by 68\% and 41\%, respectively.},
	booktitle = {2018 {IEEE} 23rd {International} {Conference} on {Digital} {Signal} {Processing} ({DSP})},
	author = {Hu, R. and Tian, B. and Yin, S. and Wei, S.},
	month = nov,
	year = {2018},
	keywords = {Basics, conventional softmax hardware implementation, deep neural network, Deep neural network, detection tasks, DNNs, Generators, Hardware, hardware architecture, integral stochastic computing, learning (artificial intelligence), Machine learning, machine learning technique, Microelectronics, multiclassification tasks, neural nets, Neural networks, pattern classification, softmax layer, Softmax Layer, stochastic processes, Table lookup, Task analysis},
	pages = {1--5},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Lisa\\Zotero\\storage\\DW69QXLV\\Hu et al. - 2018 - Efficient Hardware Architecture of Softmax Layer i.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Lisa\\Zotero\\storage\\UVAPD8QJ\\8631588.html:text/html},
}

@inproceedings{Basics-Softmax-Hardware2,
	address = {Tysons Corner VA USA},
	title = {Efficient {Softmax} {Hardware} {Architecture} for {Deep} {Neural} {Networks}},
	isbn = {978-1-4503-6252-8},
	url = {https://dl.acm.org/doi/10.1145/3299874.3317988},
	doi = {10.1145/3299874.3317988},
	abstract = {Deep neural network (DNN) has become a pivotal machine learning and object recognition technology in the big data era. The softmax layer is one of the key component layers for completing multi-classification tasks. However, the softmax layer contains complex exponential and division operations, resulting in low accuracy and long critical paths in hardware accelerator design. In order to solve the above issues, we present a softmax hardware architecture with proper accuracy, good trade-off and strong expansibility. We summarize the classification rules of neural network and balance the calculation accuracy between resource consumption. On this basis, we proposed an exponential calculation unit based on the group lookup table, and improve a natural logarithmic calculation unit based on the Maclaurin series and the data preprocessing scheme matching them. The experimental results show that the softmax hardware architecture proposed in this paper can achieve the calculation accuracy of 3 decimal fraction and the classification accuracy of 99.01\%. Theoretically, it can accomplish the classification task of infinite categories.},
	urldate = {2021-02-18},
	booktitle = {Proceedings of the 2019 on {Great} {Lakes} {Symposium} on {VLSI}},
	publisher = {ACM},
	author = {Du, Gaoming and Tian, Chao and Li, Zhenmin and Zhang, Duoli and Yin, Yongsheng and Ouyang, Yiming},
	month = may,
	year = {2019},
	keywords = {Basics, Softmax Layer},
	pages = {75--80},
	file = {Du et al. - 2019 - Efficient Softmax Hardware Architecture for Deep N.pdf:C\:\\Users\\Lisa\\Zotero\\storage\\QJ8ZRR5F\\Du et al. - 2019 - Efficient Softmax Hardware Architecture for Deep N.pdf:application/pdf},
}

@inproceedings{Basics-Dropout,
	address = {Long Beach, CA, USA},
	title = {Attention-{Based} {Dropout} {Layer} for {Weakly} {Supervised} {Object} {Localization}},
	isbn = {978-1-72813-293-8},
	url = {https://ieeexplore.ieee.org/document/8954302/},
	doi = {10.1109/CVPR.2019.00232},
	abstract = {Weakly Supervised Object Localization (WSOL) techniques learn the object location only using image-level labels, without location annotations. A common limitation for these techniques is that they cover only the most discriminative part of the object, not the entire object. To address this problem, we propose an Attention-based Dropout Layer (ADL), which utilizes the self-attention mechanism to process the feature maps of the model. The proposed method is composed of two key components: 1) hiding the most discriminative part from the model for capturing the integral extent of object, and 2) highlighting the informative region for improving the recognition power of the model. Based on extensive experiments, we demonstrate that the proposed method is effective to improve the accuracy of WSOL, achieving a new state-of-the-art localization accuracy in CUB-200-2011 dataset. We also show that the proposed method is much more efﬁcient in terms of both parameter and computation overheads than existing techniques.},
	urldate = {2021-02-18},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Choe, Junsuk and Shim, Hyunjung},
	month = jun,
	year = {2019},
	pages = {2214--2223},
	file = {Choe und Shim - 2019 - Attention-Based Dropout Layer for Weakly Supervise.pdf:C\:\\Users\\Lisa\\Zotero\\storage\\477A7T7F\\Choe und Shim - 2019 - Attention-Based Dropout Layer for Weakly Supervise.pdf:application/pdf},
}

@inproceedings{Basics-Softmax,
	title = {A {High}-{Accuracy} {Implementation} for {Softmax} {Layer} in {Deep} {Neural} {Networks}},
	doi = {10.1109/DTIS48698.2020.9081313},
	abstract = {This paper presents an efficient high-accuracy hardware implementation of softmax layer to be used in multicategory classification tasks in Deep Neural Networks (DNNs). The implementation exploits the nature of softmax input data to optimize the data pre-processing unit by applying a downscaling approach of minimal computational load. It accelerates the calculation unit by parallel processing of softmax valid data, which in turn reduces the inference time. Additionally, exponential units rely on lookup tables of stage-dependent accuracy to reduce the area overhead of processing tasks with minor effect on classification accuracy. A detailed and comparative study of the different downscaling and domain transformation schemes for softmax is provided and tuned to best fit the implementation purpose for a high-accuracy hardware-optimized softmax model. The hardware model matches the classification accuracy of the reference software model of 99.13\% and relies on single precision floating point arithmetic cores.},
	booktitle = {2020 15th {Design} {Technology} of {Integrated} {Systems} in {Nanoscale} {Era} ({DTIS})},
	author = {Alabassy, B. and Safar, M. and El-Kharashi, M. W.},
	month = apr,
	year = {2020},
	keywords = {Basics, Convolutional Neural Network (CNN), data pre-processing unit, Deep Neural Network (DNN), deep neural networks, DNNs, domain transformation schemes, downscaling approach, field programmable gate arrays, floating point arithmetic, high-accuracy hardware implementation, high-accuracy hardware-optimized softmax model, Image Classification, lookup tables, multicategory classification tasks, neural nets, parallel processing, pattern classification, single precision floating point arithmetic cores, softmax input data, softmax layer, Softmax Layer, softmax valid data, table lookup, VLSI},
	pages = {1--6},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Lisa\\Zotero\\storage\\7PB94SK3\\Alabassy et al. - 2020 - A High-Accuracy Implementation for Softmax Layer i.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Lisa\\Zotero\\storage\\95ZNSS3F\\9081313.html:text/html},
}

@article{Basics-ReLU,
	title = {Deep {Learning} using {Rectified} {Linear} {Units} ({ReLU})},
	url = {http://arxiv.org/abs/1803.08375},
	abstract = {We introduce the use of rectified linear units (ReLU) as the classification function in a deep neural network (DNN). Conventionally, ReLU is used as an activation function in DNNs, with Softmax function as their classification function. However, there have been several studies on using a classification function other than Softmax, and this study is an addition to those. We accomplish this by taking the activation of the penultimate layer \$h\_\{n - 1\}\$ in a neural network, then multiply it by weight parameters \${\textbackslash}theta\$ to get the raw scores \$o\_\{i\}\$. Afterwards, we threshold the raw scores \$o\_\{i\}\$ by \$0\$, i.e. \$f(o) = {\textbackslash}max(0, o\_\{i\})\$, where \$f(o)\$ is the ReLU function. We provide class predictions \${\textbackslash}hat\{y\}\$ through argmax function, i.e. argmax \$f(x)\$.},
	urldate = {2021-02-18},
	journal = {arXiv:1803.08375 [cs, stat]},
	author = {Agarap, Abien Fred},
	month = feb,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Basics, ReLU, ReLU Layer},
	annote = {Comment: 7 pages, 11 figures, 9 tables},
	file = {arXiv Fulltext PDF:C\:\\Users\\Lisa\\Zotero\\storage\\JI4XBX6J\\Agarap - 2019 - Deep Learning using Rectified Linear Units (ReLU).pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Lisa\\Zotero\\storage\\73DATC7C\\1803.html:text/html},
}
